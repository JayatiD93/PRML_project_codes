{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Imagenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo_46iHKlSe7"
      },
      "source": [
        "# example of a CNN model with an identity or projection residual module\n",
        "# Example of creating a CNN model with a VGG block\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Activation\n",
        "\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import add\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clxN6siBpyrX",
        "outputId": "69d66d15-855c-449d-9fc7-43daa82a68a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmZvtwmhtIFV",
        "outputId": "aba6798d-3b40-4c9f-827c-9b70bb0ff290"
      },
      "source": [
        "%cd /content/drive/MyDrive/PRML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PRML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygk9Tib-tMw0"
      },
      "source": [
        "# function for creating an identity or projection residual module\n",
        "def residual_module(layer_in, n_filters, strides=(1,1)):\n",
        "  bn_axis = 3\n",
        "  conv1 = Conv2D(n_filters, (3,3), strides=strides, padding='same', kernel_initializer='he_normal')(layer_in)\n",
        "  conv1a = BatchNormalization(axis=bn_axis)(conv1)\n",
        "  conv1a = Activation('relu')(conv1a)\n",
        "  # conv2\n",
        "  conv2 = Conv2D(n_filters, (3,3), padding='same', kernel_initializer='he_normal')(conv1a)\n",
        "  conv2 = BatchNormalization(axis=bn_axis)(conv2)\n",
        "  if strides==(1,1):\n",
        "    conv2 = add([layer_in, conv2])\n",
        "  else:\n",
        "    conv2 = add([conv1, conv2])\n",
        "  conv2 = Activation('relu')(conv2)\n",
        "  return conv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIQDC1sPtV9V"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create a new generator\n",
        "imagegen = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7VwyTrft0Ec",
        "outputId": "01f1f9be-17a2-4ece-eeb4-89ac198d4fa5"
      },
      "source": [
        "# load train data\n",
        "train = imagegen.flow_from_directory(\"/content/drive/MyDrive/PRML/imagenette2-160/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9469 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfig7LwxuA8l",
        "outputId": "c3099fd2-63cf-432c-9b16-edb42feda195"
      },
      "source": [
        "# load val data\n",
        "val = imagegen.flow_from_directory(\"/content/drive/MyDrive/PRML/imagenette2-160/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3925 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI_sBZobXZP1"
      },
      "source": [
        "## Resnet with layer = 18\n",
        "\n",
        "visible = Input(shape=(224, 224, 3))\n",
        "\n",
        "layer = Conv2D(64, (7,7),strides=(2, 2),  padding='same')(visible)\n",
        "layer = BatchNormalization()(layer)\n",
        "layer = layers.Activation(activations.relu)(layer)\n",
        "layer = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(layer)\n",
        "layer = BatchNormalization()(layer)\n",
        "layer = layers.Activation(activations.relu)(layer)\n",
        "\n",
        "\n",
        "layer =  residual_module(layer, 64)\n",
        "layer = residual_module(layer, 64)\n",
        "\n",
        "\n",
        "layer = residual_module(layer, 128, strides=(2,2))\n",
        "layer = residual_module(layer, 128)\n",
        "\n",
        "\n",
        "layer = residual_module(layer, 256, strides=(2,2))\n",
        "layer = residual_module(layer, 256)\n",
        "\n",
        "\n",
        "layer = residual_module(layer, 512, strides=(2,2))\n",
        "layer = residual_module(layer, 512)\n",
        "\n",
        "\n",
        "layer = GlobalAveragePooling2D()(layer)\n",
        "layer = Dense(10, activation='softmax')(layer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fXg9ggC0JkS"
      },
      "source": [
        "# create model\n",
        "model = Model(inputs=visible, outputs=layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwCoGS-X0OGh",
        "outputId": "95893d3a-af4b-4425-9a1a-8806facc51f3"
      },
      "source": [
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool (TFOpL (None, 56, 56, 64)   0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 56, 56, 64)   36928       tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 56, 56, 64)   36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 56, 56, 64)   0           tf.nn.relu_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 56, 56, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 64)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  73856       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 28, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 28, 128)  0           conv2d_5[0][0]                   \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 28, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 28, 28, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 128)  0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 28, 28, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 14, 14, 256)  295168      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 14, 14, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 14, 14, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 14, 14, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 14, 14, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 256)  0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 14, 14, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 14, 14, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 14, 14, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 14, 14, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 14, 14, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 14, 14, 256)  0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 14, 14, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 512)    1180160     activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 512)    2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 512)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 512)    2359808     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 512)    2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 7, 7, 512)    0           conv2d_13[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 512)    2359808     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 512)    2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 512)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 512)    2359808     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 512)    2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 7, 7, 512)    0           activation_13[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 11,019,786\n",
            "Trainable params: 11,011,850\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb3tGCXlDARP"
      },
      "source": [
        "## Resnet with layer = 34\n",
        "\n",
        "layer_34 = Conv2D(64, (7,7),strides=(2, 2),  padding='same')(visible)\n",
        "layer_34 = BatchNormalization()(layer_34)\n",
        "layer_34 = layers.Activation(activations.relu)(layer_34)\n",
        "layer_34 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(layer_34)\n",
        "layer_34 = BatchNormalization()(layer_34)\n",
        "layer_34 = layers.Activation(activations.relu)(layer_34)\n",
        "\n",
        "\n",
        "layer_34 =  residual_module(layer_34, 64)\n",
        "layer_34 = residual_module(layer_34, 64)\n",
        "layer_34 = residual_module(layer_34, 64)\n",
        "\n",
        "\n",
        "layer_34 = residual_module(layer_34, 128, strides=(2,2))\n",
        "layer_34 = residual_module(layer_34, 128)\n",
        "layer_34 = residual_module(layer_34, 128)\n",
        "layer_34 = residual_module(layer_34, 128)\n",
        "\n",
        "\n",
        "layer_34 = residual_module(layer_34, 256, strides=(2,2))\n",
        "layer_34 = residual_module(layer_34, 256)\n",
        "layer_34 = residual_module(layer_34, 256)\n",
        "layer_34 = residual_module(layer_34, 256)\n",
        "layer_34 = residual_module(layer_34, 256)\n",
        "layer_34 = residual_module(layer_34, 256)\n",
        "\n",
        "\n",
        "layer_34 = residual_module(layer_34, 512, strides=(2,2))\n",
        "layer_34 = residual_module(layer_34, 512)\n",
        "layer_34 = residual_module(layer_34, 512)\n",
        "\n",
        "\n",
        "\n",
        "layer_34 = GlobalAveragePooling2D()(layer_34)\n",
        "layer_34 = Dense(10, activation='softmax')(layer_34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DNQAtFdE2OS"
      },
      "source": [
        "# create model\n",
        "model_2 = Model(inputs=visible, outputs=layer_34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYh6F4c9E6AM",
        "outputId": "102ada99-0e4e-43e2-8b5c-600d4bed6611"
      },
      "source": [
        "# summarize model\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 112, 112, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 112, 112, 64) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_1 (TFO (None, 56, 56, 64)   0           tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 56, 56, 64)   256         tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 56, 56, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 56, 56, 64)   36928       tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 56, 56, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 56, 56, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 56, 56, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 56, 56, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 56, 56, 64)   0           tf.nn.relu_3[0][0]               \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 56, 56, 64)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 56, 56, 64)   36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 56, 56, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 56, 56, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 56, 56, 64)   36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 56, 56, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 56, 56, 64)   0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 56, 56, 64)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 56, 56, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 56, 56, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 56, 56, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 56, 56, 64)   36928       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 56, 56, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 56, 56, 64)   0           activation_19[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 56, 56, 64)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 128)  73856       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 28, 28, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 128)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 28, 28, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 28, 28, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 28, 28, 128)  0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 28, 28, 128)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 28, 28, 128)  147584      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 28, 28, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 28, 28, 128)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 28, 28, 128)  147584      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 28, 28, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 28, 28, 128)  0           activation_23[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 28, 28, 128)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 28, 28, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 28, 28, 128)  512         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 28, 28, 128)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 28, 28, 128)  147584      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 28, 28, 128)  512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 28, 28, 128)  0           activation_25[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 28, 28, 128)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 28, 28, 128)  147584      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 28, 28, 128)  512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 28, 28, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 28, 28, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 28, 28, 128)  512         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 28, 28, 128)  0           activation_27[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 28, 28, 128)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 256)  295168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 256)  590080      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 14, 14, 256)  0           conv2d_32[0][0]                  \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 14, 14, 256)  0           activation_31[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 256)  590080      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 14, 14, 256)  0           activation_33[0][0]              \n",
            "                                                                 batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 256)  590080      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 14, 14, 256)  0           activation_35[0][0]              \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 256)  0           activation_37[0][0]              \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 14, 14, 256)  590080      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 256)  1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 256)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 14, 14, 256)  590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 14, 14, 256)  1024        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 14, 14, 256)  0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 14, 14, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 512)    1180160     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 7, 7, 512)    0           conv2d_44[0][0]                  \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 7, 7, 512)    0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 7, 7, 512)    0           activation_45[0][0]              \n",
            "                                                                 batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 512)          0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           5130        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 21,139,082\n",
            "Trainable params: 21,123,722\n",
            "Non-trainable params: 15,360\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjgJYLQjFhYr"
      },
      "source": [
        "opt = SGD(learning_rate=0.1, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0bEuf-z_tvr"
      },
      "source": [
        "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDO91NGfCQAb"
      },
      "source": [
        "#trainX = model.predict(train)\n",
        "#testX = model.predict(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiguoEboChYy"
      },
      "source": [
        "#trainY = to_categorical(train.labels)\n",
        "#testY = to_categorical(val.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2JC9XK4CyLb"
      },
      "source": [
        "epoch =80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijZ06yi2s-J"
      },
      "source": [
        " #history = model.fit_generator(train, epochs=epoch, validation_data=val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS35DQ50Cqqz"
      },
      "source": [
        "#history = model.fit(trainX, trainY, epochs=epoch, batch_size=128, validation_data=(testX, testY), verbose=1)\n",
        "#history = model.fit_generator(train, epochs=epoch, validation_data=val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMVaayvGrDL"
      },
      "source": [
        "import numpy as np\n",
        "#loss_history = (1-np.array(history.history['accuracy']))*100\n",
        "#loss_history_test = (1-np.array(history.history['val_accuracy']))*100\n",
        "#numpy_loss_history = np.array(loss_history)\n",
        "#numpy_loss_history_test = np.array(loss_history_test)\n",
        "#np.savetxt(\"/content/drive/MyDrive/PRML/loss_history_imagenet1.csv\", numpy_loss_history)\n",
        "#np.savetxt(\"/content/drive/MyDrive/PRML/loss_history_imagenet2.csv\", numpy_loss_history_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK0zyoFjDbST"
      },
      "source": [
        "#pyplot.plot((1-np.array(history.history['accuracy']))*100,'g-', label='train 18-layer')\n",
        "#pyplot.plot((1-np.array(history.history['val_accuracy']))*100,'g--', label='test 18-layer')\n",
        "#pyplot.xlabel('Epoch',fontsize=12)\n",
        "#pyplot.ylabel('Error(%)',fontsize=12)\n",
        "#pyplot.legend()\n",
        "#pyplot.grid(color='y')\n",
        "#pyplot.figure(1,dpi=120)\n",
        "#pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeWzFHXeDzBy"
      },
      "source": [
        "model_2.compile(loss='mse', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGNAUnvnD8ci"
      },
      "source": [
        "#trainX_2 = model_2.predict(train)\n",
        "#testX_2 = model_2.predict(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaKQcGpyEArp"
      },
      "source": [
        "#trainY_2 = to_categorical(train.labels)\n",
        "#testY_2 = to_categorical(val.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2L1BuZiEIlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cee011-aff0-44b2-b3d8-86b836d19d29"
      },
      "source": [
        "history_2 = model_2.fit_generator(train, epochs=epoch, validation_data=val)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "74/74 [==============================] - 4693s 63s/step - loss: 0.1762 - accuracy: 0.0978 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 2/80\n",
            "74/74 [==============================] - 55s 735ms/step - loss: 0.1747 - accuracy: 0.1264 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 3/80\n",
            "74/74 [==============================] - 55s 748ms/step - loss: 0.1865 - accuracy: 0.0677 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 4/80\n",
            "74/74 [==============================] - 57s 763ms/step - loss: 0.1911 - accuracy: 0.0446 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 5/80\n",
            "74/74 [==============================] - 57s 775ms/step - loss: 0.1797 - accuracy: 0.1014 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 6/80\n",
            "74/74 [==============================] - 58s 781ms/step - loss: 0.1645 - accuracy: 0.1775 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 7/80\n",
            "74/74 [==============================] - 58s 779ms/step - loss: 0.1840 - accuracy: 0.0802 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 8/80\n",
            "74/74 [==============================] - 58s 784ms/step - loss: 0.1858 - accuracy: 0.0710 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 9/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1664 - accuracy: 0.1682 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 10/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1800 - accuracy: 0.1000 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 11/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1875 - accuracy: 0.0625 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 12/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1903 - accuracy: 0.0485 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 13/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1768 - accuracy: 0.1158 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 14/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1849 - accuracy: 0.0753 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 15/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1809 - accuracy: 0.0957 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 16/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1821 - accuracy: 0.0893 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 17/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1764 - accuracy: 0.1179 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 18/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1738 - accuracy: 0.1309 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 19/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1779 - accuracy: 0.1107 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 20/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1791 - accuracy: 0.1045 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 21/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1664 - accuracy: 0.1678 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 22/80\n",
            "74/74 [==============================] - 59s 791ms/step - loss: 0.1834 - accuracy: 0.0831 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 23/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1823 - accuracy: 0.0883 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 24/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1798 - accuracy: 0.1012 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 25/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1790 - accuracy: 0.1051 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 26/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1792 - accuracy: 0.1042 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 27/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1822 - accuracy: 0.0891 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 28/80\n",
            "74/74 [==============================] - 59s 789ms/step - loss: 0.1829 - accuracy: 0.0854 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 29/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1756 - accuracy: 0.1220 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 30/80\n",
            "74/74 [==============================] - 59s 789ms/step - loss: 0.1743 - accuracy: 0.1283 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 31/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1814 - accuracy: 0.0932 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 32/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1832 - accuracy: 0.0838 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 33/80\n",
            "74/74 [==============================] - 59s 789ms/step - loss: 0.1723 - accuracy: 0.1383 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 34/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1761 - accuracy: 0.1195 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 35/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1851 - accuracy: 0.0744 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 36/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1789 - accuracy: 0.1056 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 37/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1871 - accuracy: 0.0643 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 38/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1783 - accuracy: 0.1084 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 39/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1724 - accuracy: 0.1379 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 40/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1848 - accuracy: 0.0761 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 41/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1777 - accuracy: 0.1113 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 42/80\n",
            "74/74 [==============================] - 59s 789ms/step - loss: 0.1761 - accuracy: 0.1193 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 43/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1721 - accuracy: 0.1393 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 44/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1921 - accuracy: 0.0397 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 45/80\n",
            "74/74 [==============================] - 59s 793ms/step - loss: 0.1865 - accuracy: 0.0674 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 46/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1910 - accuracy: 0.0451 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 47/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1927 - accuracy: 0.0365 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 48/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1940 - accuracy: 0.0298 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 49/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1588 - accuracy: 0.2060 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 50/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1926 - accuracy: 0.0372 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 51/80\n",
            "74/74 [==============================] - 59s 789ms/step - loss: 0.1883 - accuracy: 0.0583 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 52/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1792 - accuracy: 0.1039 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 53/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1666 - accuracy: 0.1671 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 54/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1848 - accuracy: 0.0758 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 55/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1757 - accuracy: 0.1217 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 56/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1820 - accuracy: 0.0901 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 57/80\n",
            "74/74 [==============================] - 58s 786ms/step - loss: 0.1719 - accuracy: 0.1407 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 58/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1778 - accuracy: 0.1110 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 59/80\n",
            "74/74 [==============================] - 58s 789ms/step - loss: 0.1894 - accuracy: 0.0528 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 60/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1807 - accuracy: 0.0966 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 61/80\n",
            "74/74 [==============================] - 59s 790ms/step - loss: 0.1859 - accuracy: 0.0705 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 62/80\n",
            "74/74 [==============================] - 59s 792ms/step - loss: 0.1804 - accuracy: 0.0979 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 63/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1812 - accuracy: 0.0938 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 64/80\n",
            "74/74 [==============================] - 57s 773ms/step - loss: 0.1709 - accuracy: 0.1456 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 65/80\n",
            "74/74 [==============================] - 58s 783ms/step - loss: 0.1882 - accuracy: 0.0588 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 66/80\n",
            "74/74 [==============================] - 58s 782ms/step - loss: 0.1723 - accuracy: 0.1384 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 67/80\n",
            "74/74 [==============================] - 58s 785ms/step - loss: 0.1691 - accuracy: 0.1547 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 68/80\n",
            "74/74 [==============================] - 58s 785ms/step - loss: 0.1795 - accuracy: 0.1027 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 69/80\n",
            "74/74 [==============================] - 58s 785ms/step - loss: 0.1771 - accuracy: 0.1146 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 70/80\n",
            "74/74 [==============================] - 58s 785ms/step - loss: 0.1644 - accuracy: 0.1778 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 71/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1820 - accuracy: 0.0898 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 72/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1798 - accuracy: 0.1009 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 73/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1887 - accuracy: 0.0566 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 74/80\n",
            "74/74 [==============================] - 59s 791ms/step - loss: 0.1790 - accuracy: 0.1050 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 75/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1750 - accuracy: 0.1248 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 76/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1731 - accuracy: 0.1344 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 77/80\n",
            "74/74 [==============================] - 58s 788ms/step - loss: 0.1750 - accuracy: 0.1249 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 78/80\n",
            "74/74 [==============================] - 59s 788ms/step - loss: 0.1803 - accuracy: 0.0986 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 79/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1774 - accuracy: 0.1128 - val_loss: 0.1818 - val_accuracy: 0.0910\n",
            "Epoch 80/80\n",
            "74/74 [==============================] - 58s 787ms/step - loss: 0.1844 - accuracy: 0.0779 - val_loss: 0.1818 - val_accuracy: 0.0910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePAL650AHIfN"
      },
      "source": [
        "loss_history_2 = (1-np.array(history_2.history['accuracy']))*100\n",
        "loss_history_test_2 = (1-np.array(history_2.history['val_accuracy']))*100\n",
        "numpy_loss_history_2 = np.array(loss_history_2)\n",
        "numpy_loss_history_test_2 = np.array(loss_history_test_2)\n",
        "np.savetxt(\"/content/drive/MyDrive/PRML/loss_history_imagenet_34layer_1.csv\", numpy_loss_history_2)\n",
        "np.savetxt(\"/content/drive/MyDrive/PRML/loss_history_imagenet_34layer_2.csv\", numpy_loss_history_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJrI2dfcEU25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dd8cdf9c-d274-4030-f25f-74159457a799"
      },
      "source": [
        "pyplot.plot((1-np.array(history_2.history['accuracy']))*100,'r-', label='train 34-layer')\n",
        "pyplot.plot((1-np.array(history_2.history['val_accuracy']))*100,'r--', label='test 34-layer')\n",
        "pyplot.xlabel('Epoch',fontsize=12)\n",
        "pyplot.ylabel('Error(%)',fontsize=12)\n",
        "pyplot.legend()\n",
        "pyplot.grid(color='y')\n",
        "pyplot.figure(1,dpi=120)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K0DEYlJW0yK"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "import numpy as np\n",
        "def summarize_diagnostics(history,history_2):\n",
        "  pyplot.title('Error')\n",
        "  \n",
        "  pyplot.plot((1-np.array(history.history['accuracy']))*100,'g-', label='train 18-layer')\n",
        "  #pyplot.plot((1-np.array(history.history['val_accuracy']))*100,'g--', label='test 18-layer')\n",
        "  pyplot.plot((1-np.array(history_2.history['accuracy']))*100,'r-', label='train 34-layer')\n",
        "  #pyplot.plot((1-np.array(history_2.history['val_accuracy']))*100,'r--', label='test 34-layer')     \n",
        "  # save plot to file\n",
        "  filename = sys.argv[0].split('/')[-1]\n",
        "  #pyplot.savefig(filename + '_plot.png')\n",
        "  pyplot.xlabel('Epoch',fontsize=12)\n",
        "  pyplot.ylabel('Error(%)',fontsize=12)\n",
        "  pyplot.legend()\n",
        "  pyplot.grid(color='y')\n",
        "  pyplot.figure(1,dpi=120)\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPr6RjhYOvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "713674d0-d4c8-4c21-e8bc-daded3d336ac"
      },
      "source": [
        "#summarize_diagnostics(history,history_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5527def527a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}